{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "\n",
    "# Add the scripts folder to the Python path\n",
    "sys.path.append(os.path.abspath(\"../scripts\"))  # Adjust the path accordingly"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tokenize Data and Prepare it for FastAlign"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from preprocessing import preprocess\n",
    "\n",
    "\n",
    "ladino_file_path = '../data/tatoeba.spa-lad.lad'\n",
    "spanish_file_path = '../data/tatoeba.spa-lad.spa'\n",
    "parallel_file_path = '../data/preprocessing/parallel_spa-lad.txt'\n",
    "spanish_pos_file_path = '../data/preprocessing/spanish_pos.txt'\n",
    "\n",
    "preprocess(ladino_file_path, spanish_file_path, parallel_file_path, spanish_pos_file_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Align Tokens using FastAlign"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fatal: destination path 'fast_align' already exists and is not an empty directory.\n",
      "mkdir: cannot create directory ‘build’: File exists\n"
     ]
    }
   ],
   "source": [
    "!git clone https://github.com/clab/fast_align.git\n",
    "!cd fast_align && mkdir build && cd build && cmake .. && make"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ARG=i\n",
      "ARG=d\n",
      "ARG=o\n",
      "ARG=v\n",
      "INITIAL PASS \n",
      "expected target length = source length * 1.04245\n",
      "ITERATION 1\n",
      "  log_e likelihood: -74562.3\n",
      "  log_2 likelihood: -107571\n",
      "     cross entropy: 29.8974\n",
      "        perplexity: 1e+09\n",
      "      posterior p0: 0.08\n",
      " posterior al-feat: -0.226178\n",
      "       size counts: 49\n",
      "ITERATION 2\n",
      "  log_e likelihood: -8785.95\n",
      "  log_2 likelihood: -12675.4\n",
      "     cross entropy: 3.52291\n",
      "        perplexity: 11.4948\n",
      "      posterior p0: 0.0112663\n",
      " posterior al-feat: -0.186326\n",
      "       size counts: 49\n",
      "  1  model al-feat: -0.150993 (tension=4)\n",
      "  2  model al-feat: -0.171971 (tension=3.29333)\n",
      "  3  model al-feat: -0.181401 (tension=3.00622)\n",
      "  4  model al-feat: -0.18476 (tension=2.90771)\n",
      "  5  model al-feat: -0.185841 (tension=2.87638)\n",
      "  6  model al-feat: -0.186177 (tension=2.86668)\n",
      "  7  model al-feat: -0.186281 (tension=2.8637)\n",
      "  8  model al-feat: -0.186312 (tension=2.86279)\n",
      "     final tension: 2.86251\n",
      "ITERATION 3\n",
      "  log_e likelihood: -5552.03\n",
      "  log_2 likelihood: -8009.89\n",
      "     cross entropy: 2.22621\n",
      "        perplexity: 4.67902\n",
      "      posterior p0: 0.0163667\n",
      " posterior al-feat: -0.183834\n",
      "       size counts: 49\n",
      "  1  model al-feat: -0.186322 (tension=2.86251)\n",
      "  2  model al-feat: -0.184603 (tension=2.91227)\n",
      "  3  model al-feat: -0.184075 (tension=2.92765)\n",
      "  4  model al-feat: -0.18391 (tension=2.93246)\n",
      "  5  model al-feat: -0.183858 (tension=2.93398)\n",
      "  6  model al-feat: -0.183841 (tension=2.93446)\n",
      "  7  model al-feat: -0.183836 (tension=2.93461)\n",
      "  8  model al-feat: -0.183835 (tension=2.93465)\n",
      "     final tension: 2.93467\n",
      "ITERATION 4\n",
      "  log_e likelihood: -5201.42\n",
      "  log_2 likelihood: -7504.07\n",
      "     cross entropy: 2.08562\n",
      "        perplexity: 4.24458\n",
      "      posterior p0: 0.0212829\n",
      " posterior al-feat: -0.182254\n",
      "       size counts: 49\n",
      "  1  model al-feat: -0.183834 (tension=2.93467)\n",
      "  2  model al-feat: -0.182755 (tension=2.96626)\n",
      "  3  model al-feat: -0.182415 (tension=2.97628)\n",
      "  4  model al-feat: -0.182306 (tension=2.97949)\n",
      "  5  model al-feat: -0.182271 (tension=2.98052)\n",
      "  6  model al-feat: -0.18226 (tension=2.98085)\n",
      "  7  model al-feat: -0.182256 (tension=2.98096)\n",
      "  8  model al-feat: -0.182255 (tension=2.98099)\n",
      "     final tension: 2.981\n",
      "ITERATION 5 (FINAL)\n",
      "  log_e likelihood: -5111.36\n",
      "  log_2 likelihood: -7374.13\n",
      "     cross entropy: 2.04951\n",
      "        perplexity: 4.13965\n",
      "      posterior p0: 0\n",
      " posterior al-feat: 0\n",
      "       size counts: 49\n"
     ]
    }
   ],
   "source": [
    "! fast_align/build/fast_align -i ../data/preprocessing/parallel_spa-lad.txt -d -o -v > ../data/preprocessing/alignments.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Transfer POS Tags from Spanish to Ladino using alignments"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Transfer tags for one sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def transfer_pos_tag(ladino_sent, alignment, pos_tags):\n",
    "    \"\"\"Takes in a sentence from Ladino, alignments with Spanish, and the Spanish Part of Speech tags\n",
    "    and transfers the tags to the Ladino sentence\n",
    "    \"\"\"\n",
    "    ladino_pos = [\"UNK\"] * len(ladino_sent) # tags are unknown by default\n",
    "\n",
    "    for lad_idx, spa_idx in alignment:\n",
    "        if spa_idx < len(pos_tags):  # Ensure alignment is within bounds\n",
    "            ladino_pos[lad_idx] = pos_tags[spa_idx]\n",
    "    \n",
    "    return ladino_pos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create file to keep track of Ladino POS tags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "from load_preprocessed_data import load_alignments, load_parallel_data, load_spanish_pos\n",
    "alignments = load_alignments('../data/preprocessing/alignments.txt')\n",
    "ladino_tokens, spanish_tokens = load_parallel_data(parallel_file_path)\n",
    "spanish_pos = load_spanish_pos(spanish_pos_file_path)\n",
    "\n",
    "with open('../data/weak/ladino-pos.txt', \"w\", encoding=\"utf-8\") as f:\n",
    "        for sentence, alignment, pos_tags in zip(ladino_tokens, alignments, spanish_pos):\n",
    "            pos_tags = transfer_pos_tag(sentence, alignment, pos_tags)\n",
    "            formatted = \" \".join(f\"{word} ({tag})\" for word, tag in zip(sentence, pos_tags)) + \"\\n\"\n",
    "            f.write(formatted)\n",
    "        f.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
