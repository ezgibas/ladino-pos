{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "\n",
    "# Add the scripts folder to the Python path\n",
    "sys.path.append(os.path.abspath(\"../scripts\"))  # Adjust the path accordingly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from preprocessing import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train, test = load_tagged_sentences(\"../data/brown-universal.txt\", split=0.8)\n",
    "tags = load_tags(\"../data/tags-universal.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"There are {} sentences in the training set.\".format(len(train)))\n",
    "print(\"There are {} sentences in the testing set.\".format(len(test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# partition train so only a few of the samples are used for the initial probabilities\n",
    "train_sample = train[:500]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print_results = False\n",
    "\n",
    "\"\"\"\n",
    "Count tags, tag transitions, and emissions of words to create the proper probability tables:\n",
    "P(Tag)\n",
    "P(Tag_{i} | Tag_{i-1})\n",
    "P(Word | Tag)\n",
    "\"\"\"\n",
    "def create_count_dictionaries(data):\n",
    "    tag_counts = {} # P(Tag)\n",
    "    tag_transition_counts = {} # P(Tag_{i} | Tag_{i-1})\n",
    "    # go through each sentence in the data\n",
    "    for sentence in data:\n",
    "        tags_sequence = [word.get_pos() for word in sentence]\n",
    "        words_sequence = [word.get_word() for word in sentence]\n",
    "        prev_tag = \"<s>\" # all sentences start with delimiter\n",
    "        # go through each word and tag\n",
    "        for _, tag in zip(words_sequence, tags_sequence):\n",
    "            # P(Tag)\n",
    "            tag_counts[tag] = tag_counts.get(tag, 0) + 1\n",
    "\n",
    "            # P(Tag_{i} | Tag_{i-1})\n",
    "            tag_transition = (prev_tag, tag) # make key to indicate transitioning from the previous tag to current\n",
    "            tag_transition_counts[tag_transition] = tag_transition_counts.get(tag_transition, 0) + 1\n",
    "            prev_tag = tag\n",
    "        \n",
    "        # P(Tag_{i} | Tag_{i-1}) only for the end of the sentence\n",
    "        tag_transition = (prev_tag, \"<s/>\") # all sentences end with delimiter\n",
    "        tag_transition_counts[tag_transition] = tag_transition_counts.get(tag_transition, 0) + 1\n",
    "    return tag_counts, tag_transition_counts\n",
    "\n",
    "tag_counts, tag_transition_counts = create_count_dictionaries(train_sample)\n",
    "\n",
    "if print_results:\n",
    "    tag_counts = sorted(tag_counts.items(), key=lambda item: item[1], reverse=True)\n",
    "    tag_transition_counts = sorted(tag_transition_counts.items(), key=lambda item: item[1], reverse=True)\n",
    "    print(tag_counts)\n",
    "    print(tag_transition_counts)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Make actual probability tables out of counts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a matrix for Tag -> Tag transitions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tags = sorted(tags) # columns\n",
    "num_tags = len(tags)\n",
    "\n",
    "tags_matrix = np.zeros((num_tags, num_tags), dtype='float32')\n",
    "\n",
    "tag_to_index = {tag: j for j, tag in enumerate(tags)}\n",
    "\n",
    "for tag_1 in tags:\n",
    "    for tag_2 in tags:\n",
    "        i = tag_to_index[tag_1]\n",
    "        j = tag_to_index[tag_2]\n",
    "        count_of_transition = tag_transition_counts.get((tag_1, tag_2), 0)\n",
    "        tags_matrix[i, j] = count_of_transition/tag_counts.get(tag_1)\n",
    "\n",
    "\n",
    "tags_matrix = np.where(tags_matrix == 0.0, 1e-6, tags_matrix)\n",
    "tags_matrix = np.log(tags_matrix)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tags_matrix_df = pd.DataFrame(tags_matrix, columns = tags, index=tags)\n",
    "tags_matrix_df = np.exp(tags_matrix_df)\n",
    "tags_matrix_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a matrix for Tag -> Word probabilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tags_dict = word_to_tag_counts(train)\n",
    "words = list(tags_dict.keys())  # rows\n",
    "# columns are \"tags\" defined in previous cell\n",
    "\n",
    "# create mapping of words and tags to an index so that we can\n",
    "# add to the correct tag/word every time we are updating the matrix5\n",
    "word_to_index = {word: i for i, word in enumerate(words)}\n",
    "\n",
    "emission_matrix = np.zeros((len(tags), len(words)))\n",
    "\n",
    "for word, counter in tags_dict.items():\n",
    "    for tag, count in counter.items():\n",
    "        emission_matrix[tag_to_index[tag], word_to_index[word]] = count\n",
    "\n",
    "\n",
    "emission_matrix = emission_matrix / emission_matrix.sum(axis=1, keepdims=True)\n",
    "\n",
    "emission_matrix = np.where(emission_matrix == 0.0, 1e-6, emission_matrix)\n",
    "emission_matrix = np.log(emission_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ems_matrix_df = pd.DataFrame(emission_matrix, columns = list(words), index=list(tags))\n",
    "ems_matrix_df = np.exp(ems_matrix_df)\n",
    "ems_matrix_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create initial probabilities matrix (the probability a sentence starts with a tag)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "initial_probs = np.zeros(len(tags))\n",
    "for i in range(len(tags)):\n",
    "    prob = tag_transition_counts.get(('<s>', tags[i]), 0)\n",
    "    initial_probs[i] = prob\n",
    "\n",
    "initial_probs = initial_probs / initial_probs.sum()\n",
    "\n",
    "initial_probs = np.where(initial_probs == 0.0, 1e-6, initial_probs)\n",
    "initial_probs = np.log(initial_probs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "initial_probs_df = pd.DataFrame([initial_probs], columns = tags)\n",
    "initial_probs_df = np.exp(initial_probs_df)\n",
    "initial_probs_df"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
